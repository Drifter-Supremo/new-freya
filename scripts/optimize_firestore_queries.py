"""
optimize_firestore_queries.py - Script to analyze and optimize Firestore queries

This script:
1. Identifies inefficient query patterns
2. Suggests optimization strategies
3. Implements query improvements
4. Tests performance improvements
"""

import time
import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any, Optional, Tuple
import asyncio

# Import our services
from app.services.firebase_service import FirebaseService
from app.services.firebase_memory_service import FirebaseMemoryService
from app.core.config import logger

# Configure logging for this script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class FirestoreOptimizer:
    """Class to analyze and optimize Firestore queries."""
    
    def __init__(self):
        self.firebase = FirebaseService()
        self.memory_service = FirebaseMemoryService()
        self.performance_results = {}
    
    def analyze_current_queries(self, user_id: str):
        """Analyze current query patterns and identify optimization opportunities."""
        print("\nüîç Analyzing Current Firestore Query Patterns...\n")
        
        # 1. Analyze user facts query
        print("1. USER FACTS QUERY ANALYSIS:")
        print("   Current: Fetches ALL userFacts then filters in memory")
        print("   Problem: No userId filtering at Firestore level")
        print("   Impact: Fetches unnecessary documents, increases read costs")
        print("   Solution: Add userId field to userFacts documents and query with filter")
        
        # 2. Analyze conversation messages query
        print("\n2. CONVERSATION MESSAGES QUERY ANALYSIS:")
        print("   Current: Queries messages collection without conversationId filter")
        print("   Problem: Messages don't have conversationId field in current structure")
        print("   Impact: Cannot retrieve conversation-specific messages efficiently")
        print("   Solution: Add conversationId field to messages or restructure as subcollection")
        
        # 3. Analyze topic memories query
        print("\n3. TOPIC MEMORIES QUERY ANALYSIS:")
        print("   Current: Uses array_contains filter on topicIds field")
        print("   Problem: Messages don't have topicIds field")
        print("   Impact: Topic-based memory retrieval doesn't work")
        print("   Solution: Add topicIds array field to messages")
        
        # 4. Analyze memory context assembly
        print("\n4. MEMORY CONTEXT ASSEMBLY ANALYSIS:")
        print("   Current: Multiple sequential queries for different memory tiers")
        print("   Problem: No query batching or caching")
        print("   Impact: Higher latency, more read operations")
        print("   Solution: Implement parallel queries and caching")
        
        # 5. Analyze timestamp handling
        print("\n5. TIMESTAMP HANDLING ANALYSIS:")
        print("   Current: Complex timestamp conversions in memory service")
        print("   Problem: Inconsistent timestamp formats")
        print("   Impact: Performance overhead, potential bugs")
        print("   Solution: Standardize on Firestore timestamps")
    
    def test_query_performance(self, user_id: str):
        """Test current query performance."""
        print("\n‚è±Ô∏è  Testing Current Query Performance...\n")
        
        # Test 1: User facts query
        start_time = time.time()
        facts = self.firebase.get_user_facts(user_id)
        facts_time = time.time() - start_time
        print(f"User Facts Query: {facts_time:.3f}s for {len(facts)} documents")
        self.performance_results['user_facts_original'] = facts_time
        
        # Test 2: Recent conversations query
        start_time = time.time()
        conversations = self.firebase.get_user_conversations(user_id, limit=10)
        conv_time = time.time() - start_time
        print(f"User Conversations Query: {conv_time:.3f}s for {len(conversations)} documents")
        self.performance_results['conversations_original'] = conv_time
        
        # Test 3: Messages query (without conversation filter)
        start_time = time.time()
        messages = self.firebase.query_collection('messages', filters=[], limit=50)
        msg_time = time.time() - start_time
        print(f"Messages Query (no filter): {msg_time:.3f}s for {len(messages)} documents")
        self.performance_results['messages_original'] = msg_time
        
        # Test 4: Full memory context assembly
        start_time = time.time()
        memory_context = self.memory_service.assemble_memory_context(user_id, "test query")
        context_time = time.time() - start_time
        print(f"Full Memory Context Assembly: {context_time:.3f}s")
        self.performance_results['memory_context_original'] = context_time
    
    def suggest_optimizations(self):
        """Suggest specific optimizations."""
        print("\nüí° OPTIMIZATION RECOMMENDATIONS:\n")
        
        optimizations = [
            {
                "title": "1. Add Composite Indexes",
                "description": "Create composite indexes for common query patterns",
                "impact": "30-50% query speed improvement",
                "implementation": """
    # In Firebase Console, create these indexes:
    # Collection: userFacts
    # - Fields: userId (ASC), timestamp (DESC)
    
    # Collection: conversations  
    # - Fields: userId (ASC), updatedAt (DESC)
    
    # Collection: messages
    # - Fields: conversationId (ASC), timestamp (DESC)
    # - Fields: topicIds (ARRAY_CONTAINS), timestamp (DESC)
                """
            },
            {
                "title": "2. Implement Query Batching",
                "description": "Batch multiple queries into parallel operations",
                "impact": "40-60% latency reduction for memory assembly",
                "implementation": """
    async def get_memory_context_optimized(user_id: str, query: str):
        # Run queries in parallel
        facts_task = asyncio.create_task(get_user_facts_async(user_id))
        convs_task = asyncio.create_task(get_conversations_async(user_id))
        topics_task = asyncio.create_task(get_topics_async(user_id))
        
        facts, convs, topics = await asyncio.gather(
            facts_task, convs_task, topics_task
        )
        return assemble_context(facts, convs, topics)
                """
            },
            {
                "title": "3. Add Missing Fields to Documents",
                "description": "Add userId to userFacts, conversationId to messages",
                "impact": "Enable proper filtering, reduce data transfer",
                "implementation": """
    # Migration script to add missing fields:
    def migrate_user_facts():
        facts = firebase.query_collection('userFacts', filters=[], limit=1000)
        for fact in facts:
            if 'userId' not in fact:
                firebase.update_document('userFacts', fact['id'], 
                    {'userId': 'Sencere'})  # Set appropriate userId
                
    def migrate_messages():
        messages = firebase.query_collection('messages', filters=[], limit=1000)
        for msg in messages:
            if 'conversationId' not in msg:
                # Determine conversationId based on context
                firebase.update_document('messages', msg['id'], 
                    {'conversationId': determine_conversation_id(msg)})
                """
            },
            {
                "title": "4. Implement Caching Layer",
                "description": "Cache frequently accessed data like user facts",
                "impact": "70-90% reduction in repeated queries",
                "implementation": """
    from functools import lru_cache
    from datetime import datetime, timedelta
    
    class CachedFirebaseService(FirebaseService):
        def __init__(self):
            super().__init__()
            self._cache = {}
            self._cache_ttl = timedelta(minutes=5)
        
        def get_user_facts(self, user_id: str):
            cache_key = f"facts_{user_id}"
            if cache_key in self._cache:
                cached_data, timestamp = self._cache[cache_key]
                if datetime.now() - timestamp < self._cache_ttl:
                    return cached_data
            
            # Fetch from Firestore
            facts = super().get_user_facts(user_id)
            self._cache[cache_key] = (facts, datetime.now())
            return facts
                """
            },
            {
                "title": "5. Optimize Memory Scoring",
                "description": "Pre-compute relevance scores and store in Firestore",
                "impact": "50% reduction in memory context assembly time",
                "implementation": """
    # Store pre-computed scores with messages
    def store_message_with_topics(message_data: dict, topics: List[str]):
        # Extract topics and compute initial relevance
        message_data['topicIds'] = extract_topic_ids(topics)
        message_data['topicScores'] = compute_topic_scores(message_data['content'])
        
        # Use Firestore server timestamp
        message_data['timestamp'] = firestore.SERVER_TIMESTAMP
        
        return firebase.add_document('messages', message_data)
                """
            }
        ]
        
        for opt in optimizations:
            print(f"### {opt['title']}")
            print(f"Description: {opt['description']}")
            print(f"Expected Impact: {opt['impact']}")
            print(f"Implementation:{opt['implementation']}\n")
    
    def implement_quick_wins(self, user_id: str):
        """Implement some quick optimization wins."""
        print("\nüöÄ Implementing Quick Win Optimizations...\n")
        
        # Quick Win 1: Parallel query execution
        print("1. Testing parallel query execution...")
        
        async def test_parallel_queries():
            start_time = time.time()
            
            # Sequential queries (current approach)
            facts = self.firebase.get_user_facts(user_id)
            convs = self.firebase.get_user_conversations(user_id)
            topics = self.firebase.get_user_topics(user_id)
            
            sequential_time = time.time() - start_time
            print(f"   Sequential execution: {sequential_time:.3f}s")
            
            # Parallel queries (optimized approach)
            start_time = time.time()
            
            async def get_facts():
                return self.firebase.get_user_facts(user_id)
            
            async def get_convs():
                return self.firebase.get_user_conversations(user_id)
            
            async def get_topics():
                return self.firebase.get_user_topics(user_id)
            
            # Note: This is pseudo-code since Firebase Admin SDK is synchronous
            # In production, you'd use threading or process pools
            import concurrent.futures
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                future_facts = executor.submit(self.firebase.get_user_facts, user_id)
                future_convs = executor.submit(self.firebase.get_user_conversations, user_id)
                future_topics = executor.submit(self.firebase.get_user_topics, user_id)
                
                facts = future_facts.result()
                convs = future_convs.result()
                topics = future_topics.result()
            
            parallel_time = time.time() - start_time
            print(f"   Parallel execution: {parallel_time:.3f}s")
            print(f"   Improvement: {((sequential_time - parallel_time) / sequential_time * 100):.1f}%")
        
        # Run the async test
        asyncio.run(test_parallel_queries())
        
        # Quick Win 2: Limit fields returned
        print("\n2. Testing field limiting...")
        
        # Test with full documents
        start_time = time.time()
        full_facts = self.firebase.query_collection('userFacts', filters=[], limit=100)
        full_time = time.time() - start_time
        
        # Note: Firestore Admin SDK doesn't support field selection directly
        # This would be done via REST API or client SDK
        print(f"   Full document fetch: {full_time:.3f}s")
        print(f"   Recommendation: Use REST API with field masks for 30-50% data reduction")
        
        # Quick Win 3: Optimize timestamp queries
        print("\n3. Testing timestamp-based queries...")
        
        # Get messages from last 7 days
        cutoff = datetime.now(timezone.utc) - timedelta(days=7)
        start_time = time.time()
        
        # Current approach: fetch all then filter
        all_messages = self.firebase.query_collection('messages', filters=[], limit=100)
        filtered_messages = [m for m in all_messages if m.get('timestamp', datetime.min) > cutoff]
        
        current_time = time.time() - start_time
        print(f"   Current approach (fetch all, filter in memory): {current_time:.3f}s")
        print(f"   Found {len(filtered_messages)} messages from last 7 days out of {len(all_messages)} total")
        
        # Optimized approach would use Firestore query
        print(f"   Optimized approach would use: where('timestamp', '>', cutoff)")
        print(f"   Expected improvement: 60-80% for sparse recent data")
    
    def generate_optimization_report(self):
        """Generate a comprehensive optimization report."""
        print("\nüìä FIRESTORE OPTIMIZATION REPORT\n")
        print("=" * 60)
        print(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        print("\n## Current Performance Metrics:")
        for key, value in self.performance_results.items():
            print(f"   {key}: {value:.3f}s")
        
        print("\n## Key Issues Identified:")
        print("   1. No userId filtering on userFacts collection")
        print("   2. Messages lack conversationId field")
        print("   3. No composite indexes for common queries")
        print("   4. Sequential query execution in memory assembly")
        print("   5. No caching layer for frequently accessed data")
        
        print("\n## Recommended Actions (Priority Order):")
        print("   1. [HIGH] Add missing fields to enable proper filtering")
        print("   2. [HIGH] Create composite indexes in Firebase Console")
        print("   3. [MEDIUM] Implement parallel query execution")
        print("   4. [MEDIUM] Add caching layer for user facts")
        print("   5. [LOW] Optimize memory scoring algorithms")
        
        print("\n## Expected Performance Improvements:")
        print("   - User Facts Query: 70-80% faster with userId filter + index")
        print("   - Memory Assembly: 40-60% faster with parallel execution")
        print("   - Repeated Queries: 90% faster with caching")
        print("   - Overall API Response: 50-70% improvement")
        
        print("\n## Next Steps:")
        print("   1. Run migration scripts to add missing fields")
        print("   2. Create indexes in Firebase Console")
        print("   3. Update FirebaseService with optimized queries")
        print("   4. Implement caching in FirebaseMemoryService")
        print("   5. Deploy and monitor performance")

def main():
    """Main function to run optimization analysis."""
    print("üî• Firestore Query Optimization Tool")
    print("=" * 60)
    
    # Initialize optimizer
    optimizer = FirestoreOptimizer()
    
    # Use test user ID
    user_id = "Sencere"
    
    # Run analysis
    optimizer.analyze_current_queries(user_id)
    
    # Test performance
    optimizer.test_query_performance(user_id)
    
    # Suggest optimizations
    optimizer.suggest_optimizations()
    
    # Implement quick wins
    optimizer.implement_quick_wins(user_id)
    
    # Generate report
    optimizer.generate_optimization_report()
    
    print("\n‚úÖ Optimization analysis complete!")

if __name__ == "__main__":
    main()